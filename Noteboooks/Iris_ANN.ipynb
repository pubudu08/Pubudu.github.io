{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Flowers Dataset: Machine Learning Problem.\n",
    "\n",
    "### Dataset \n",
    "\n",
    "This dataset is well studied and is a good problem for practicing on ANN because of the four input variables and neumaric and have same scale in centimeters. Each instance describes the properites of an observed flower measurements and the output variable is specific iris species. \n",
    "\n",
    "Therefore, it's a multi-class problem, meaning that there are more than two classes to be predicted, in fact there are three flower species. This is an important type of problem on which to practice with ANN because the three class values require specilized handling. \n",
    "\n",
    "**Goal: Model accuracy of 95%-97%**\n",
    "\n",
    "### Technology description.\n",
    "\n",
    "#### Why Keras? \n",
    "It is a Python library for deep learning that wraps the efficeint numerical libraries Theano and TensorFlow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize random number generator to constant value, which is 7. This is important to ensure that the result we achieve from model can be achieved again precisely. It ensures that the stochastic process of training an ANN model can be reproduced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed_value = 7\n",
    "np.random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5.1</th>\n",
       "      <th>3.5</th>\n",
       "      <th>1.4</th>\n",
       "      <th>0.2</th>\n",
       "      <th>Iris-setosa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   5.1  3.5  1.4  0.2  Iris-setosa\n",
       "0  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "1  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "2  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "3  5.0  3.6  1.4  0.2  Iris-setosa\n",
       "4  5.4  3.9  1.7  0.4  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset \n",
    "dataframe = pd.read_csv('datasets/Multi-class_Classification/Iris/iris.data.txt')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataframe.values\n",
    "X = dataset[:,0:4].astype(float)\n",
    "Y = dataset[:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to Y's nature, we need to create dummy variables from a categorical variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers \n",
    "label_encoder = LabelEncoder()\n",
    "#creating the dummy varibales  \n",
    "Y = label_encoder.fit_transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avoiding dummy variable trap\n",
    "# have to remove one dummy variable away, you don't need all three types\n",
    "dummy_y = dummy_y[:, 1:]  \n",
    "dummy_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size = 0.2, random_state = 0)\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # Initialising the ANN\n",
    "    # 4 inputs -> [8 hidden nodes] -> 3 outputs\n",
    "    classifier = Sequential()\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = 4))\n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(units = 2, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "    # Compiling the ANN\n",
    "    classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation \n",
    "The gold standard for evaluating machine learning models is k-fold cross validation. Evaluating the model only takes approximately 10 seconds and returns an object that describes the evaluation of the 10 constructed models for each of the splits of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 96.62% (5.41%)\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "By doing this project I learned:\n",
    "* How to load data and make it available to Keras.\n",
    "* How to prepare multi-class classification data for modeling using one hot encoding.\n",
    "* How to deal with categorical variables \n",
    "* How to use Keras neural network models with scikit-learn.\n",
    "* How to define a neural network using Keras for multi-class classification.\n",
    "* How to evaluate a Keras neural network model using scikit-learn with k-fold cross validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
